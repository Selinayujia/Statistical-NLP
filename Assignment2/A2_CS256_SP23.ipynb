{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1K-yEsHe9c4B6vBiL24t91BCovRN5ZP1a","timestamp":1678432932615},{"file_id":"1qWfGHzKDt2o0AuFEDJB3FAg_J6GE52nG","timestamp":1646435194169},{"file_id":"1Sl6tl-dL32oI5gEcofa-9Orjh9BWQkB7","timestamp":1646435132542},{"file_id":"12lyhUy6ZAN2BO8lCOUrdLG7cxkD2KrB4","timestamp":1646253268722},{"file_id":"1cTDpMUuJbxxaGEcNe11KQXLLweu8OA8r","timestamp":1646026402023},{"file_id":"1CRZfedkwWd5_NAIVp1vo6bz5xYkyTFgC","timestamp":1634149359597},{"file_id":"1K9H753cX0tD0lsoXvyHsDhrTtbnzq1bL","timestamp":1603002079306},{"file_id":"18v_7cFNT362Lzcmyg_PNKVnGQgVKc3i2","timestamp":1602459467767},{"file_id":"1bcAXWjkz8V8PK1FhnBrsb5YZAHKJiVFe","timestamp":1601580687210},{"file_id":"1wgo33YMqyTmwPXBCgDYvDD39Hgz516zV","timestamp":1599667757648},{"file_id":"1ZNQQshRjVp-0vLNi6ZGRtXX102EWHRq4","timestamp":1598302241860},{"file_id":"1XOa--UHuAQpBRcdqYbFcb8QuUTvywsSk","timestamp":1568522504552},{"file_id":"1LShMg_-e2SzrjDMxSgVbnYyTAgwcJov0","timestamp":1568420694683}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"332ea832aa3c4ad9a03950045c9676c5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cd175c24b1d94bd69eb0ab364cd2305f","IPY_MODEL_f3ce85b842244d9c85f56698c2ee7b31","IPY_MODEL_790fa1e9eb0642b09fc6a7f93f4bf7e0"],"layout":"IPY_MODEL_77f3fc9b7238493ebb126e82e3445792"}},"cd175c24b1d94bd69eb0ab364cd2305f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1206fdc1df11415794ede6ecfd1eb8e0","placeholder":"​","style":"IPY_MODEL_bf7fa10903814ad0a896a8343fe1ea27","value":"Downloading pytorch_model.bin: 100%"}},"f3ce85b842244d9c85f56698c2ee7b31":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3fa3eb5312df4010b582af6c1a3fe1d5","max":440473133,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d06432b8cd0d493e888e915ec0d04c6e","value":440473133}},"790fa1e9eb0642b09fc6a7f93f4bf7e0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_21f0ea7ed03f470bbfc6c2839beb2a05","placeholder":"​","style":"IPY_MODEL_f54a2c1e6bb54e65a428e4429cd88959","value":" 440M/440M [00:03&lt;00:00, 135MB/s]"}},"77f3fc9b7238493ebb126e82e3445792":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1206fdc1df11415794ede6ecfd1eb8e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf7fa10903814ad0a896a8343fe1ea27":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3fa3eb5312df4010b582af6c1a3fe1d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d06432b8cd0d493e888e915ec0d04c6e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"21f0ea7ed03f470bbfc6c2839beb2a05":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f54a2c1e6bb54e65a428e4429cd88959":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"SgNZTjrhcHa0"},"source":["# CSE 256: Statistical NLP UCSD Assignment 2\n","## Text Classification with Pretrained Language Models (40 points)\n","### <font color='blue'> Due: Friday May 12, 2023 at  10pm </font>\n","\n","###### IMPORTANT: After copying this notebook to your Google Drive, paste a link to it below. To get a publicly-accessible link, click the *Share* button at the top right, then click \"Get shareable link\" and copy the link. \n","#### <font color=\"red\">Link: paste your link here:  </font>\n","\n","\n","\n","---\n","**Notes:**\n","\n","Make sure to save the notebook as you go along.\n","\n","Submission instructions are located at the bottom of the notebook."]},{"cell_type":"markdown","source":["# Part 1: Data Collection\n","\n","In this assignment, you will first identify or annotate a text dataset, with at least **120 labeled sentences** (more is better),  for a text classification task of your choice. Any text data is fine: e.g., news articles, reviews, legal docs, medical docs.  The dataset should allow you to create a **binary text classification task (two labels only)**. Feel free to look at  [Hugging Face datasets](https://huggingface.co/datasets) or  [Kaggle](https://www.kaggle.com/datasets?fileType=csv), or other places.  \n","\n","*You are welcome to annotate your own dataset, just make sure it is not a task that is trivally solvable*.\n"],"metadata":{"id":"DnocitP0wari"}},{"cell_type":"markdown","source":["## Question 1.1 (10 points):\n","Give a brief summary of the dataset you picked.\n","Biefly describe the text classification task, and why it is a non-trivial task.\n","Provide basic statistics of the dataset (include: how many labeled examples, how many unique words) \n","\n"],"metadata":{"id":"AdZg5OFuyn7P"}},{"cell_type":"markdown","source":["#### <font color=\"red\">Write your answer here (< 6 sentences) </font>\n","\n","\n"],"metadata":{"id":"f5S2pJxjzSKX"}},{"cell_type":"markdown","metadata":{"id":"d23zfO_ALKeB"},"source":["# Part 2: Text classification"]},{"cell_type":"markdown","metadata":{"id":"N25dvF4jvYoy"},"source":["In this part, you will fine-tune  pretrained language models on your dataset. This part is meant to be an introduction to the HuggingFace library, and it contains code that will potentially be useful for your final projecs. Since we're dealing with large models, the first step is to change to a GPU runtime.\n","\n","## Adding a hardware accelerator\n","\n","Go to the menu and add a GPU as follows:\n","\n","`Edit > Notebook Settings > Hardware accelerator > (GPU)`\n","\n","Run the following cell to confirm that the GPU is detected."]},{"cell_type":"code","metadata":{"id":"edOh9ooiIW1B","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682746299153,"user_tz":420,"elapsed":2110,"user":{"displayName":"Ndapandula Nakashole","userId":"15450062936262242698"}},"outputId":"d284a287-3e06-49cf-ede0-1c1160ecb799"},"source":["import torch\n","\n","# Confirm that the GPU is detected\n","\n","assert torch.cuda.is_available()\n","\n","# Get the GPU device name.\n","device_name = torch.cuda.get_device_name()\n","n_gpu = torch.cuda.device_count()\n","print(f\"Found device: {device_name}, n_gpu: {n_gpu}\")\n","device = torch.device(\"cuda\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found device: Tesla T4, n_gpu: 1\n"]}]},{"cell_type":"markdown","metadata":{"id":"xrvH7xx9LnMC"},"source":["## Installing Hugging Face's Transformers library\n","We will use Hugging Face's Transformers (https://github.com/huggingface/transformers), an open-source library that provides general-purpose architectures for natural language understanding and generation with a collection of various pretrained models made by the NLP community. This library will allow us to easily use pretrained models like `BERT` and perform experiments on top of them. We can use these models to solve downstream target tasks, such as text classification, question answering, and sequence labeling.\n","\n","Run the following cell to install Hugging Face's Transformers library and download a sample data file called tweets.csv that contains tweets about airlines along with a negative, neutral, or positive sentiment rating. Note that you will be asked to link with your Google Drive account to download some of these files. If you're concerned about security risks (there have not been any issues in previous semesters), feel free to make a new Google account and use it for this assignment! alternatively, you can manually download the files from our [Google drive](https://drive.google.com/drive/folders/1M6JwwGXS5RpylWe7G9TEmC5a7PtrMMQk?usp=sharing), and read them directly in your notebook instead of using the PyDrive API."]},{"cell_type":"code","metadata":{"id":"gtqS2e5fxpqa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682746324259,"user_tz":420,"elapsed":11327,"user":{"displayName":"Ndapandula Nakashole","userId":"15450062936262242698"}},"outputId":"8820b42a-da8a-4603-8b8f-43c65037d18c"},"source":["!pip install transformers\n","!pip install -U -q PyDrive\n","\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","# Authenticate and create the PyDrive client.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","print('success!')\n","\n","import os\n","import zipfile\n","\n","# Download helper functions file\n","helper_file = drive.CreateFile({'id': '1XHV97dCHMmsekJyXRduB9Q0sCWLylwrh'})\n","helper_file.GetContentFile('helpers.py')\n","print('helper file downloaded! (helpers.py)')\n","\n","# Download sample file of tweets                      \n","data_file = drive.CreateFile({'id': '1pJephA7sBxMbshTtzLAhtzjQrwkfJSzu'})\n","data_file.GetContentFile('tweets.csv')\n","print('sample tweets downloaded! (tweets.csv)')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.28.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n","success!\n","helper file downloaded! (helpers.py)\n","sample tweets downloaded! (tweets.csv)\n"]}]},{"cell_type":"markdown","metadata":{"id":"-8XIL7wPovVX"},"source":["The cell below imports some helper functions to demonstrate the task on the sample tweet dataset."]},{"cell_type":"code","metadata":{"id":"Taseb33Sovg0"},"source":["from helpers import tokenize_and_format, flat_accuracy"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gKc0xYh-MAbc"},"source":["# Data Prep and Model Specification\n","\n","Upload your data using the file explorer to the left. We have provided a function below to tokenize and format your data as BERT requires. Make sure that your csv file, titled **my_data.csv**, has one column \"text\" and another column \"labels\" containing integers. If your dataset comes pre-split, you may choose just the train split for the purpose of this assignment, or you may combine the splits into one single file. We will doing our own data split.\n","\n","If you run the cell below without modifications, it will run on the tweets.csv example data we have provided. It imports some helper functions to demonstrate the task on the sample tweet dataset. You should first run all of the following cells with tweets.csv just to see how everything works. Then, once you understand the whole preprocessing / fine-tuning process, change the csv in the below cell to your **my_data.csv** file, add any extra preprocessing code you wish, and then run the cells again on your own data."]},{"cell_type":"code","metadata":{"id":"YGhkeLQlNNr8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682746451916,"user_tz":420,"elapsed":288,"user":{"displayName":"Ndapandula Nakashole","userId":"15450062936262242698"}},"outputId":"2e2fc9c1-833a-4848-beca-a4b72f291589"},"source":["from helpers import tokenize_and_format, flat_accuracy\n","import pandas as pd\n","\n","#df = pd.read_csv('my_data.csv')\n","df = pd.read_csv('tweets.csv')\n","\n","df = df.sample(frac=1).reset_index(drop=True)\n","\n","texts = df.text.values\n","labels = df.label.values\n","\n","### tokenize_and_format() is a helper function provided in helpers.py ###\n","input_ids, attention_masks = tokenize_and_format(texts)\n","\n","# Convert the lists into tensors.\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","labels = torch.tensor(labels)\n","\n","# Print sentence 0, now as a list of IDs.\n","print('Original: ', texts[0])\n","print('Token IDs:', input_ids[0])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Original:  @VirginAmerica has flight number 276 from SFO to Cabo San Lucas arrived yet?\n","Token IDs: tensor([  101,  1030,  6261, 14074, 14735,  2038,  3462,  2193, 25113,  2013,\n","        16420,  2080,  2000,  9298,  2080,  2624,  6326,  3369,  2664,  1029,\n","          102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0])\n"]}]},{"cell_type":"markdown","metadata":{"id":"H3D-CzQEUXYz"},"source":["## Create train/test/validation splits\n","\n","Here we split your dataset into 3 parts: a training set, a validation set, and a testing set. Each item in your dataset will be a 3-tuple containing an input_id tensor, an attention_mask tensor, and a label tensor.\n","\n"]},{"cell_type":"code","metadata":{"id":"kGgeZ3M0UWs0"},"source":["\n","total = len(df)\n","\n","num_train = int(total * .8)\n","num_val = int(total * .1)\n","num_test = total - num_train - num_val\n","\n","# make lists of 3-tuples (already shuffled the dataframe in cell above)\n","\n","train_set = [(input_ids[i], attention_masks[i], labels[i]) for i in range(num_train)]\n","val_set = [(input_ids[i], attention_masks[i], labels[i]) for i in range(num_train, num_val+num_train)]\n","test_set = [(input_ids[i], attention_masks[i], labels[i]) for i in range(num_val + num_train, total)]\n","\n","train_text = [texts[i] for i in range(num_train)]\n","val_text = [texts[i] for i in range(num_train, num_val+num_train)]\n","test_text = [texts[i] for i in range(num_val + num_train, total)]\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QCr006iTkqwM"},"source":["Here we choose the model we want to finetune from https://huggingface.co/transformers/pretrained_models.html. Because the task requires us to label sentences, we wil be using BertForSequenceClassification below. You may see a warning that states that `some weights of the model checkpoint at [model name] were not used when initializing. . .` This warning is expected and means that you should fine-tune your pre-trained model before using it on your downstream task. See [here](https://github.com/huggingface/transformers/issues/5421#issuecomment-652582854) for more info."]},{"cell_type":"code","metadata":{"id":"lPo640_ZlEPK","colab":{"base_uri":"https://localhost:8080/","height":962,"referenced_widgets":["332ea832aa3c4ad9a03950045c9676c5","cd175c24b1d94bd69eb0ab364cd2305f","f3ce85b842244d9c85f56698c2ee7b31","790fa1e9eb0642b09fc6a7f93f4bf7e0","77f3fc9b7238493ebb126e82e3445792","1206fdc1df11415794ede6ecfd1eb8e0","bf7fa10903814ad0a896a8343fe1ea27","3fa3eb5312df4010b582af6c1a3fe1d5","d06432b8cd0d493e888e915ec0d04c6e","21f0ea7ed03f470bbfc6c2839beb2a05","f54a2c1e6bb54e65a428e4429cd88959"]},"executionInfo":{"status":"ok","timestamp":1682746539950,"user_tz":420,"elapsed":15720,"user":{"displayName":"Ndapandula Nakashole","userId":"15450062936262242698"}},"outputId":"8f101176-c4b1-4ab9-e892-ca422bf09c13"},"source":["from transformers import BertForSequenceClassification, AdamW, BertConfig\n","\n","model = BertForSequenceClassification.from_pretrained(\n","    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n","    num_labels = 3, # The number of output labels.   \n","    output_attentions = False, # Whether the model returns attentions weights.\n","    output_hidden_states = False, # Whether the model returns all hidden-states.\n",")\n","\n","# Tell pytorch to run this model on the GPU.\n","model.cuda()\n"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"332ea832aa3c4ad9a03950045c9676c5"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",")"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"i3lLdoW_le3M"},"source":["# <font color=\"red\"> ACTION REQUIRED </font>\n","\n","Define your approach to fine-tuning hyperparameters in the cell below (we have randomly picked some values to start with). We want you to experiment with different configurations to find the one that works best (i.e., highest accuracy) on your validation set. Feel free to also change pretrained models to others available in the HuggingFace library (you'll have to modify the cell above to do this). You might find papers on BERT fine-tuning stability (e.g., [Mosbach et al., ICLR 2021](https://openreview.net/pdf?id=nzpLWnVAyah)) to be of interest."]},{"cell_type":"code","metadata":{"id":"Dd2JdC6IletV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682746595842,"user_tz":420,"elapsed":7,"user":{"displayName":"Ndapandula Nakashole","userId":"15450062936262242698"}},"outputId":"4ca6e404-1c1a-4b29-c506-d8f94ede1c3c"},"source":["batch_size = 99\n","optimizer = AdamW(model.parameters(),\n","                  lr = 5e-5, # args.learning_rate - default is 5e-5\n","                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8\n","                )\n","epochs = 5"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}]},{"cell_type":"markdown","metadata":{"id":"Pd4fwn_el1ge"},"source":["# Fine-tune your model\n","Here we provide code for fine-tuning your model, monitoring the loss, and checking your validation accuracy. Rerun both of the below cells when you change your hyperparameters above."]},{"cell_type":"code","metadata":{"id":"O_Mzr-kd5RaY"},"source":["import numpy as np\n","# function to get validation accuracy\n","def get_validation_performance(val_set):\n","    # Put the model in evaluation mode\n","    model.eval()\n","\n","    # Tracking variables \n","    total_eval_accuracy = 0\n","    total_eval_loss = 0\n","\n","    num_batches = int(len(val_set)/batch_size) + 1\n","\n","    total_correct = 0\n","\n","    for i in range(num_batches):\n","\n","      end_index = min(batch_size * (i+1), len(val_set))\n","\n","      batch = val_set[i*batch_size:end_index]\n","      \n","      if len(batch) == 0: continue\n","\n","      input_id_tensors = torch.stack([data[0] for data in batch])\n","      input_mask_tensors = torch.stack([data[1] for data in batch])\n","      label_tensors = torch.stack([data[2] for data in batch])\n","      \n","      # Move tensors to the GPU\n","      b_input_ids = input_id_tensors.to(device)\n","      b_input_mask = input_mask_tensors.to(device)\n","      b_labels = label_tensors.to(device)\n","        \n","      # Tell pytorch not to bother with constructing the compute graph during\n","      # the forward pass, since this is only needed for backprop (training).\n","      with torch.no_grad():        \n","\n","        # Forward pass, calculate logit predictions.\n","        outputs = model(b_input_ids, \n","                                token_type_ids=None, \n","                                attention_mask=b_input_mask,\n","                                labels=b_labels)\n","        loss = outputs.loss\n","        logits = outputs.logits\n","            \n","        # Accumulate the validation loss.\n","        total_eval_loss += loss.item()\n","        \n","        # Move logits and labels to CPU\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","\n","        # Calculate the number of correctly labeled examples in batch\n","        pred_flat = np.argmax(logits, axis=1).flatten()\n","        labels_flat = label_ids.flatten()\n","        num_correct = np.sum(pred_flat == labels_flat)\n","        total_correct += num_correct\n","        \n","    # Report the final accuracy for this validation run.\n","    avg_val_accuracy = total_correct / len(val_set)\n","    return avg_val_accuracy\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HTf_ipbjWNoV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682746621248,"user_tz":420,"elapsed":10119,"user":{"displayName":"Ndapandula Nakashole","userId":"15450062936262242698"}},"outputId":"0a4d18fa-40cd-4916-d65d-49f46bf58c6f"},"source":["import random\n","\n","# training loop\n","\n","# For each epoch...\n","for epoch_i in range(0, epochs):\n","    # Perform one full pass over the training set.\n","\n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    # Reset the total loss for this epoch.\n","    total_train_loss = 0\n","\n","    # Put the model into training mode.\n","    model.train()\n","\n","    # For each batch of training data...\n","    num_batches = int(len(train_set)/batch_size) + 1\n","\n","    for i in range(num_batches):\n","      end_index = min(batch_size * (i+1), len(train_set))\n","\n","      batch = train_set[i*batch_size:end_index]\n","\n","      if len(batch) == 0: continue\n","\n","      input_id_tensors = torch.stack([data[0] for data in batch])\n","      input_mask_tensors = torch.stack([data[1] for data in batch])\n","      label_tensors = torch.stack([data[2] for data in batch])\n","\n","      # Move tensors to the GPU\n","      b_input_ids = input_id_tensors.to(device)\n","      b_input_mask = input_mask_tensors.to(device)\n","      b_labels = label_tensors.to(device)\n","\n","      # Clear the previously calculated gradient\n","      model.zero_grad()        \n","\n","      # Perform a forward pass (evaluate the model on this training batch).\n","      outputs = model(b_input_ids, \n","                            token_type_ids=None, \n","                            attention_mask=b_input_mask, \n","                            labels=b_labels)\n","      loss = outputs.loss\n","      logits = outputs.logits\n","\n","      total_train_loss += loss.item()\n","\n","      # Perform a backward pass to calculate the gradients.\n","      loss.backward()\n","\n","      # Update parameters and take a step using the computed gradient.\n","      optimizer.step()\n","        \n","    # ========================================\n","    #               Validation\n","    # ========================================\n","    # After the completion of each training epoch, measure our performance on\n","    # our validation set. Implement this function in the cell above.\n","    print(f\"Total loss: {total_train_loss}\")\n","    val_acc = get_validation_performance(val_set)\n","    print(f\"Validation accuracy: {val_acc}\")\n","    \n","print(\"\")\n","print(\"Training complete!\")\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","======== Epoch 1 / 5 ========\n","Training...\n","Total loss: 2.262203335762024\n","Validation accuracy: 0.5263157894736842\n","\n","======== Epoch 2 / 5 ========\n","Training...\n","Total loss: 2.123536467552185\n","Validation accuracy: 0.47368421052631576\n","\n","======== Epoch 3 / 5 ========\n","Training...\n","Total loss: 2.073915958404541\n","Validation accuracy: 0.42105263157894735\n","\n","======== Epoch 4 / 5 ========\n","Training...\n","Total loss: 1.961907148361206\n","Validation accuracy: 0.5263157894736842\n","\n","======== Epoch 5 / 5 ========\n","Training...\n","Total loss: 1.7281976342201233\n","Validation accuracy: 0.47368421052631576\n","\n","Training complete!\n"]}]},{"cell_type":"markdown","metadata":{"id":"J9DpRJE5mHkO"},"source":["# Evaluate your model on the test set\n","After you're satisfied with your hyperparameters (i.e., you're unable to achieve higher validation accuracy by modifying them further), it's time to evaluate your model on the test set! Run the below cell to compute test set accuracy.\n"]},{"cell_type":"code","metadata":{"id":"msvZ78ii3cZZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682746639588,"user_tz":420,"elapsed":306,"user":{"displayName":"Ndapandula Nakashole","userId":"15450062936262242698"}},"outputId":"518ab1d6-fe13-472a-ad42-de935916f8cb"},"source":["get_validation_performance(test_set)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.6666666666666666"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"IcMT5aih8xEb"},"source":["## Question 2.1 (10 points):\n","Congratulations! You've now gone through the entire fine-tuning process and created a model for your downstream task. Describe your hyperparameter selection process in words. If you based your process on any research papers or websites, please reference them. Why do you think the hyperparameters you ended up choosing worked better than others? Also, is there a significant discrepancy between your test and validation accuracy? Why do you think this is the case?"]},{"cell_type":"markdown","source":["#### <font color=\"red\">Write your answer here </font>"],"metadata":{"id":"YuQajggF2FPq"}},{"cell_type":"markdown","metadata":{"id":"NBbdMwt79fIs"},"source":["## Question 2.2 (20 points):\n","(Involves both coding, and a written answer)\n","Finally, perform an *error analysis* on your model. This is good practice for your final project. **Write some code** in the below code cell to print out the text five test set examples that your model gets **wrong**. If your model gets more than five test examples wrong, randomly choose five of them to analyze. If your model gets fewer than five examples wrong, please design five test examples that fool your model (i.e., *adversarial examples*). Then, in the following text cell, perform a qualitative analysis of these examples. See if you can figure out any reasons for errors that you observe, or if you have any informed guesses (e.g., common linguistic properties of these particular examples). Does this analysis suggest any possible future steps to improve your classifier?"]},{"cell_type":"code","source":["## Write your code in this cell\n","## print out up to 5 test set examples (or adversarial examples) that your model gets wrong"],"metadata":{"id":"Z9n9b34q3YlP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### <font color=\"red\">Provide a qualitative analysis of the above examples here. \n"," </font>\n","\n"],"metadata":{"id":"F3iIs7xw2DMy"}},{"cell_type":"markdown","metadata":{"id":"szIkBDiQ_Mkv"},"source":["\n","\n","# <font color=\"blue\"> Submission Instructions</font>\n","\n","1. Click the Save button at the top of the Jupyter Notebook.\n","2. Select Edit -> Clear All Outputs. This will clear all the outputs from all cells (but will keep the content of all cells). \n","3. Select Runtime -> Run All. This will run all the cells in order, and will take several minutes.\n","4. Once you've rerun everything, select File -> Download as -> PDF via LaTeX (If you have trouble using \"PDF via LaTex\", you can also save the webpage as pdf. <font color='blue'> Make sure all your solutions especially the coding parts are displayed in the pdf</font>, it's okay if the provided codes get cut off because lines are not wrapped in code cells).\n","5. Look at the PDF file and make sure all your solutions are there, displayed correctly. The PDF is the only thing your graders will see!\n","6. Submit your PDF on Gradescope.\n","\n","\n","#### <font color=\"blue\"> Acknowledgements</font>\n","This assignment is based on an assignment developed by Mohit Iyyer\n"]}]}